#!/usr/bin/env python3
"""
í‚¤ì›Œë“œë³„ ì‚¬ì´í´ ë¡œê±°

ê° í‚¤ì›Œë“œë§ˆë‹¤ ë³„ë„ì˜ ë¡œê·¸ íŒŒì¼ì„ ìƒì„±í•˜ê³  ìµœì‹  50ê°œë§Œ ìœ ì§€í•©ë‹ˆë‹¤.
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional


class KeywordLogger:
    """í‚¤ì›Œë“œë³„ ì‚¬ì´í´ ë¡œê·¸ ê´€ë¦¬"""

    def __init__(self, base_dir: str = "/home/tech/rank_screenshot/logs/keyword_cycles"):
        """
        Args:
            base_dir: ë¡œê·¸ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.base_dir = Path(base_dir)

        # umaskë¥¼ ì¼ì‹œì ìœ¼ë¡œ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ 777 ê¶Œí•œìœ¼ë¡œ ë””ë ‰í† ë¦¬ ìƒì„±
        import os
        old_umask = os.umask(0)
        try:
            self.base_dir.mkdir(parents=True, mode=0o777, exist_ok=True)
        finally:
            os.umask(old_umask)

        # ë””ë ‰í† ë¦¬ ê¶Œí•œ ëª…ì‹œì  ì„¤ì •
        try:
            os.chmod(self.base_dir, 0o777)
        except (PermissionError, OSError):
            pass  # ê¶Œí•œ ë³€ê²½ ë¶ˆê°€ ì‹œ ë¬´ì‹œ

    def _get_log_file(self, keyword: str) -> Path:
        """
        í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ìƒì„±

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ

        Returns:
            ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        """
        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        safe_keyword = "".join(c if c.isalnum() or c in ('-', '_') else '_' for c in keyword)
        return self.base_dir / f"{safe_keyword}.jsonl"

    def log_cycle(
        self,
        keyword: str,
        worker_id: str,
        cycle_data: Dict[str, Any]
    ):
        """
        í‚¤ì›Œë“œ ì‚¬ì´í´ ë¡œê·¸ ì¶”ê°€

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            worker_id: ì›Œì»¤ ID (ì˜ˆ: "Worker-1")
            cycle_data: ì‚¬ì´í´ ë°ì´í„°
                - success: bool
                - matched_product: Dict
                - match_condition: str
                - rank: int
                - original_rank: int (Adjust ëª¨ë“œ)
                - is_adjusted: bool (Adjust ëª¨ë“œ)
                - screenshot_path: str
                - error_message: str
                - pages_searched: int
                - total_products_checked: int
                - execution_time: float
        """
        log_file = self._get_log_file(keyword)

        # ë¡œê·¸ ì—”íŠ¸ë¦¬ ìƒì„±
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "worker_id": worker_id,
            "keyword": keyword,
            **cycle_data
        }

        # ê¸°ì¡´ ë¡œê·¸ ì½ê¸°
        existing_logs = []
        if log_file.exists():
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    existing_logs = [json.loads(line) for line in f if line.strip()]
            except Exception as e:
                print(f"âš ï¸  ê¸°ì¡´ ë¡œê·¸ ì½ê¸° ì‹¤íŒ¨: {e}")
                existing_logs = []

        # ìƒˆ ë¡œê·¸ ì¶”ê°€
        existing_logs.append(log_entry)

        # ìµœì‹  50ê°œë§Œ ìœ ì§€
        if len(existing_logs) > 50:
            existing_logs = existing_logs[-50:]

        # ë¡œê·¸ íŒŒì¼ ì“°ê¸°
        try:
            with open(log_file, 'w', encoding='utf-8') as f:
                for log in existing_logs:
                    f.write(json.dumps(log, ensure_ascii=False) + '\n')
        except Exception as e:
            print(f"âš ï¸  ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")

    def get_recent_logs(self, keyword: str, limit: int = 10) -> list:
        """
        ìµœê·¼ ë¡œê·¸ ì¡°íšŒ

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            limit: ì¡°íšŒí•  ë¡œê·¸ ê°œìˆ˜ (ê¸°ë³¸: 10)

        Returns:
            ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ (ìµœì‹ ìˆœ)
        """
        log_file = self._get_log_file(keyword)

        if not log_file.exists():
            return []

        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = [json.loads(line) for line in f if line.strip()]
            return logs[-limit:]
        except Exception as e:
            print(f"âš ï¸  ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_statistics(self, keyword: str) -> Optional[Dict[str, Any]]:
        """
        í‚¤ì›Œë“œë³„ í†µê³„ ì¡°íšŒ

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ

        Returns:
            í†µê³„ ì •ë³´ (ì„±ê³µë¥ , í‰ê·  ì‹¤í–‰ì‹œê°„ ë“±)
        """
        logs = self.get_recent_logs(keyword, limit=50)

        if not logs:
            return None

        total = len(logs)
        success_count = sum(1 for log in logs if log.get('success', False))

        execution_times = [log.get('execution_time', 0) for log in logs if log.get('execution_time')]
        avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0

        # Adjust ëª¨ë“œ í†µê³„
        adjusted_count = sum(1 for log in logs if log.get('is_adjusted', False))

        return {
            "keyword": keyword,
            "total_cycles": total,
            "success_count": success_count,
            "success_rate": success_count / total * 100 if total > 0 else 0,
            "avg_execution_time": avg_execution_time,
            "adjusted_count": adjusted_count,
            "adjusted_rate": adjusted_count / total * 100 if total > 0 else 0
        }

    def cleanup_old_logs(self, days: int = 7):
        """
        ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì •ë¦¬

        Args:
            days: ë³´ê´€ ê¸°ê°„ (ì¼)
        """
        import time
        cutoff_time = time.time() - (days * 86400)

        for log_file in self.base_dir.glob("*.jsonl"):
            try:
                if log_file.stat().st_mtime < cutoff_time:
                    log_file.unlink()
                    print(f"ğŸ§¹ ì˜¤ë˜ëœ ë¡œê·¸ ì‚­ì œ: {log_file.name}")
            except Exception as e:
                print(f"âš ï¸  ë¡œê·¸ ì‚­ì œ ì‹¤íŒ¨ ({log_file.name}): {e}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    logger = KeywordLogger()

    # ë¡œê·¸ ì¶”ê°€
    logger.log_cycle(
        keyword="ë…¸íŠ¸ë¶íŒŒìš°ì¹˜",
        worker_id="Worker-1",
        cycle_data={
            "success": True,
            "rank": 7,
            "original_rank": 1,
            "is_adjusted": True,
            "screenshot_path": "/path/to/screenshot.png",
            "execution_time": 68.5,
            "pages_searched": 1,
            "total_products_checked": 27
        }
    )

    # ìµœê·¼ ë¡œê·¸ ì¡°íšŒ
    recent = logger.get_recent_logs("ë…¸íŠ¸ë¶íŒŒìš°ì¹˜", limit=5)
    print(f"\nğŸ“Š ìµœê·¼ 5ê°œ ë¡œê·¸:")
    for log in recent:
        print(f"   {log['timestamp']}: {'âœ…' if log['success'] else 'âŒ'} ìˆœìœ„ {log.get('rank', 'N/A')}")

    # í†µê³„ ì¡°íšŒ
    stats = logger.get_statistics("ë…¸íŠ¸ë¶íŒŒìš°ì¹˜")
    if stats:
        print(f"\nğŸ“ˆ í†µê³„:")
        print(f"   ì´ ì‚¬ì´í´: {stats['total_cycles']}íšŒ")
        print(f"   ì„±ê³µë¥ : {stats['success_rate']:.1f}%")
        print(f"   í‰ê·  ì‹¤í–‰ì‹œê°„: {stats['avg_execution_time']:.1f}ì´ˆ")
        print(f"   DOM ì¡°ì‘: {stats['adjusted_count']}íšŒ ({stats['adjusted_rate']:.1f}%)")
